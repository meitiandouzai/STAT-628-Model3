{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dacc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3deae11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['Year']=data['Year'].astype('category')\n",
    "data['Month']=data['Month'].astype('category')\n",
    "data['DayOfWeek']=data['DayOfWeek'].astype('category')\n",
    "data['Operating_Airline ']=data['Operating_Airline '].astype('category')\n",
    "data['Origin']=data['Origin'].astype('category')\n",
    "data['Dest']=data['Dest'].astype('category')\n",
    "data['DepTimeBlk'] = data['DepTimeBlk'].astype('category')\n",
    "data['ArrTimeBlk'] = data['ArrTimeBlk'].astype('category')\n",
    "data['Origin_HourlyWindDirection'] = data['Origin_HourlyWindDirection'].astype('category')\n",
    "data['Dest_HourlyWindDirection'] = data['Dest_HourlyWindDirection'].astype('category')\n",
    "data['Holiday'] = data['Holiday'].astype('category')\n",
    "data['Cancelled'] = data['Cancelled'].astype('category')\n",
    "data = data.drop(columns=['ActualElapsedTime'])\n",
    "\n",
    "continuous_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "data = data[data['Cancelled'] != 1]\n",
    "min_arr_delay = data['ArrDelay'].min()\n",
    "data = data[data['ArrDelay'] != min_arr_delay]  # Remove row with minimum ArrDelay\n",
    "data = data.dropna(subset=['ArrDelay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41dce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_delay(delay):\n",
    "    if delay <= 0:\n",
    "        return \"OnTime\"\n",
    "    elif delay <= 30:\n",
    "        return \"SlightDelay\"\n",
    "    else:\n",
    "        return \"SevereDelay\"\n",
    "\n",
    "data['DelayCategory'] = data['ArrDelay'].apply(categorize_delay)\n",
    "data['DelayCategory'] = data['DelayCategory'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f86086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###data = data.sample(frac=0.2, random_state=42)\n",
    "\n",
    "X = data.drop(columns=['Cancelled', 'DepDelay', 'ArrDelay','DelayCategory'])\n",
    "y_class = data['DelayCategory']  \n",
    "y_reg = data['ArrDelay']  \n",
    "\n",
    "\n",
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_class, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f0b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.481886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4623\n",
      "[LightGBM] [Info] Number of data points in the train set: 7607753, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -0.402052\n",
      "[LightGBM] [Info] Start training from score -2.239300\n",
      "[LightGBM] [Info] Start training from score -1.493787\n",
      "Classification Accuracy: 0.6763176947315345\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      OnTime       0.68      0.99      0.81   1272279\n",
      " SevereDelay       0.56      0.08      0.14    203697\n",
      " SlightDelay       0.43      0.02      0.03    425963\n",
      "\n",
      "    accuracy                           0.68   1901939\n",
      "   macro avg       0.56      0.36      0.33   1901939\n",
      "weighted avg       0.61      0.68      0.56   1901939\n",
      "\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.853027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4620\n",
      "[LightGBM] [Info] Number of data points in the train set: 5089178, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -14.275002\n",
      "Results for category 'OnTime':\n",
      "  MSE: 2619.739723879378\n",
      "  MAE: 20.75977995210859\n",
      "  R²: -0.10370380472042107\n",
      "-----\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.281421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4649\n",
      "[LightGBM] [Info] Number of data points in the train set: 1708098, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 11.121478\n",
      "Results for category 'SlightDelay':\n",
      "  MSE: 3292.8632749314197\n",
      "  MAE: 29.211416173426734\n",
      "  R²: -0.07251236791685\n",
      "-----\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 810477, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 96.144885\n",
      "Results for category 'SevereDelay':\n",
      "  MSE: 13640.00021890037\n",
      "  MAE: 82.76025492398699\n",
      "  R²: -0.11122860959676939\n",
      "-----\n",
      "All results: {'OnTime': {'Mean Squared Error': 2619.739723879378, 'Mean Absolute Error': 20.75977995210859, 'R² Score': -0.10370380472042107}, 'SlightDelay': {'Mean Squared Error': 3292.8632749314197, 'Mean Absolute Error': 29.211416173426734, 'R² Score': -0.07251236791685}, 'SevereDelay': {'Mean Squared Error': 13640.00021890037, 'Mean Absolute Error': 82.76025492398699, 'R² Score': -0.11122860959676939}}\n",
      "Overall Metrics:\n",
      "Mean Squared Error (MSE): 2797.5849454346526\n",
      "Root Mean Squared Error (RMSE): 52.89220117781687\n",
      "Mean Absolute Error (MAE): 21.803370269068054\n",
      "R² Score: -0.07266935418705911\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(y_class.unique()),  \n",
    "    metric='multi_logloss',\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    random_state=42\n",
    ")\n",
    "lgb_classifier.fit(X_train, y_class_train, categorical_feature=categorical_features)\n",
    "\n",
    "y_class_pred = lgb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_class_test, y_class_pred)\n",
    "print(\"Classification Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_class_test, y_class_pred))\n",
    "\n",
    "X_test['PredictedCategory'] = y_class_pred  \n",
    "results = {}\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for category in y_class_train.unique():\n",
    "    # data\n",
    "    X_train_cat = X_train[y_class_train == category]\n",
    "    y_train_cat = y_reg_train[y_class_train == category]\n",
    "    \n",
    "    X_test_cat = X_test[X_test['PredictedCategory'] == category].drop(columns=['PredictedCategory'])\n",
    "    y_test_cat = y_reg_test[X_test['PredictedCategory'] == category]\n",
    "    \n",
    "    # check\n",
    "    if len(X_train_cat) == 0 or len(X_test_cat) == 0:\n",
    "        print(f\"Skipping category {category} due to insufficient data.\")\n",
    "        continue\n",
    "\n",
    "    # LightGBM for regression\n",
    "    lgb_regressor = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_regressor.fit(X_train_cat, y_train_cat, categorical_feature=categorical_features)\n",
    "    \n",
    "    # regrsesion predict\n",
    "    y_pred_cat = lgb_regressor.predict(X_test_cat)\n",
    "    all_y_true.extend(y_test_cat)\n",
    "    all_y_pred.extend(y_pred_cat)\n",
    "    \n",
    "    # evaluate\n",
    "    mse = mean_squared_error(y_test_cat, y_pred_cat)\n",
    "    mae = mean_absolute_error(y_test_cat, y_pred_cat)\n",
    "    r2 = r2_score(y_test_cat, y_pred_cat)\n",
    "    \n",
    "    results[category] = {\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R² Score\": r2\n",
    "    }\n",
    "    print(f\"Results for category '{category}':\")\n",
    "    print(f\"  MSE: {mse}\")\n",
    "    print(f\"  MAE: {mae}\")\n",
    "    print(f\"  R²: {r2}\")\n",
    "    print(\"-----\")\n",
    "\n",
    "# print output\n",
    "print(\"All results:\", results)\n",
    "overall_mse = mean_squared_error(all_y_true, all_y_pred)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "overall_mae = mean_absolute_error(all_y_true, all_y_pred)\n",
    "overall_r2 = r2_score(all_y_true, all_y_pred)\n",
    "print(\"Overall Metrics:\")\n",
    "print(\"Mean Squared Error (MSE):\", overall_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", overall_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", overall_mae)\n",
    "print(\"R² Score:\", overall_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
